dataset: "datasets/math_10k.json"
eval_dataset: "gsm8k+svamp+mawps"
per_device_train_batch_size: 8
num_train_epochs: 3
learning_rate: 3e-4
lr_scheduler_type: cosine
warmup_ratio: 0.04
eval_strategy: "no"
save_strategy: "no"
logging_steps: 1
peft: "lora"
bf16: true
lora_dropout: 0.0
ddp_find_unused_parameters: false
